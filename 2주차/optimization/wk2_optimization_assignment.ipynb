{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37965242, 0.87960957, 0.86964474])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X,parameters)\n",
    "    p = 1 / (1+math.exp(-z))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116428099439732"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m} \\left[ y^{(i)} \\log\\left( h_\\theta(x^{(i)}) \\right) + (1 - y^{(i)}) \\log\\left( 1 - h_\\theta(x^{(i)}) \\right) \\right] $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X,parameters)\n",
    "    loss = -y * math.log(p) - (1-y) * math.log(1-p)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = dot_product(X,parameters)\n",
    "    loss = (y-y_hat)**2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X,y,parameters)\n",
    "    loss = loss / n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3436805700053172"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)= \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)^2$ \n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)= \\nabla l(p) = \\frac{1}{m} \\sum_{i=1}^{m} \\left( h_p(x^{(i)}) - y^{(i)} \\right) \\mathbf{x}^{(i)}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = dot_product(X,parameters)\n",
    "        gradient = (y_hat-y)*X[j]\n",
    "    else:\n",
    "        p = logistic(X,parameters)\n",
    "        gradient = (p-y) * X[j]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11470672963937743"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'C:/Users/rhskr/Desktop/배치알고리즘_구현.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\display.py:1032\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\formatters.py:973\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    970\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 973\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\display.py:1022\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m   1021\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[1;32m-> 1022\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43malways_both\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[0;32m   1024\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\display.py:1034\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'C:/Users/rhskr/Desktop/배치알고리즘_구현.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'C:/Users/rhskr/Desktop/배치알고리즘_구현.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\display.py:1032\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    341\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\display.py:1054\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[1;32m-> 1054\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\IPython\\core\\display.py:1034\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1035\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'C:/Users/rhskr/Desktop/배치알고리즘_구현.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"C:/Users/rhskr/Desktop/배치알고리즘_구현.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.15971413395222"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명: batch_size로 정확하게 나누어 지지 않더라도 +1을 해서 모든 데이터 포인트가 배치에 포함되도록 하였습니다. 그 다음 배치 인덱스를 저장할 리스트를 구성합니다. 슬라이싱으로 i번째 배치에 대한 데이터를 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    gradients = np.array(gradients)\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n\n",
    "    \n",
    "    parameters -= gradients\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradients1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36mstep\u001b[1;34m(parameters, gradients, learning_rate, n)\u001b[0m\n\u001b[0;32m      2\u001b[0m gradients \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(gradients)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(parameters)):\n\u001b[1;32m----> 4\u001b[0m     gradients[i] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m/\u001b[39m n\n\u001b[0;32m      6\u001b[0m parameters \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m gradients\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parameters\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch:  \n",
    "- num_epoch:\n",
    "<br>\n",
    "\n",
    "BGD: \"...\"  \n",
    "SGD: \"...\"  \n",
    "MGD: \"...\"  \n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> \"...\"  \n",
    "batch_size=k -> \"...\"  \n",
    "batch_size=whole -> \"...\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = parameters - (learning_rate * np.array(gradients) / len(idx))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(idx))\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epoch = 1000\n",
    "tolerance = 0.00001\n",
    "model = 'logistic'  # You can choose 'logistic' for logistic regression or 'linear' for linear regression\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.7092772820544093  params: [0.94290762 0.65779928 0.34265737]  gradients: 4.4960439766347715\n",
      "epoch: 100  loss: 0.5701593889495097  params: [ 0.19352812 -0.09158023 -0.40672213]  gradients: 2.112230429472249\n",
      "epoch: 200  loss: 0.5599786248956186  params: [ 0.18137548 -0.10373286 -0.41887477]  gradients: 2.0648832794992016\n",
      "epoch: 300  loss: 0.5597941043008633  params: [ 0.1811521  -0.10395624 -0.41909815]  gradients: 2.064017962375194\n",
      "epoch: 400  loss: 0.5597906914297556  params: [ 0.18114797 -0.10396037 -0.41910228]  gradients: 2.0640019551494757\n",
      "epoch: 500  loss: 0.5597906282820088  params: [ 0.18114789 -0.10396045 -0.41910235]  gradients: 2.064001658969797\n",
      "epoch: 600  loss: 0.5597906271135892  params: [ 0.18114789 -0.10396045 -0.41910236]  gradients: 2.064001653489599\n",
      "epoch: 700  loss: 0.5597906270919696  params: [ 0.18114789 -0.10396045 -0.41910236]  gradients: 2.064001653388198\n",
      "epoch: 800  loss: 0.5597906270915697  params: [ 0.18114789 -0.10396045 -0.41910236]  gradients: 2.064001653386322\n",
      "epoch: 900  loss: 0.5597906270915625  params: [ 0.18114789 -0.10396045 -0.41910236]  gradients: 2.0640016533862875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.18114789, -0.10396045, -0.41910236])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train, learning_rate,num_epoch,tolerance,model,batch_size)\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "x0H5tnauLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.6161855916119547  params: [0.96313306 0.3745403  0.42481493]  gradients: 4.422256189624308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.43976614, -0.14882662, -0.098552  ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train,learning_rate,num_epoch,tolerance,model,batch_size)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "iGfXGoJaLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 1.3452321708497472  params: [0.63583934 0.34724836 0.35568705]  gradients: 4.132747586593097\n",
      "epoch: 100  loss: 0.5365442374493554  params: [ 0.0163457  -0.27224529 -0.2638066 ]  gradients: 1.8881980192483308\n",
      "epoch: 200  loss: 0.5291165800973081  params: [ 0.00588883 -0.28270215 -0.27426347]  gradients: 1.8498690939108613\n",
      "epoch: 300  loss: 0.5289655326550549  params: [ 0.00567329 -0.2829177  -0.27447901]  gradients: 1.8490842849491862\n",
      "epoch: 400  loss: 0.5289623996528853  params: [ 0.00566882 -0.28292217 -0.27448348]  gradients: 1.8490680042844798\n",
      "epoch: 500  loss: 0.5289623346420459  params: [ 0.00566873 -0.28292226 -0.27448357]  gradients: 1.8490676664542778\n",
      "epoch: 600  loss: 0.5289623332930377  params: [ 0.00566872 -0.28292226 -0.27448357]  gradients: 1.8490676594441282\n",
      "epoch: 700  loss: 0.528962333265045  params: [ 0.00566872 -0.28292226 -0.27448357]  gradients: 1.8490676592986635\n",
      "epoch: 800  loss: 0.5289623332644643  params: [ 0.00566872 -0.28292226 -0.27448357]  gradients: 1.8490676592956454\n",
      "epoch: 900  loss: 0.5289623332644525  params: [ 0.00566872 -0.28292226 -0.27448357]  gradients: 1.8490676592955844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00566872, -0.28292226, -0.27448357])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_mgd = gradient_descent(X_train, y_train, learning_rate,num_epoch,tolerance,model,batch_size)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22, 18],\n",
       "       [ 6,  4]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46681346, 2.47569008])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "M74iqj4WLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: -0.06016895152668422  params: [0.11422273 0.62775907]  gradients: -5.751560648747889\n",
      "epoch: 100  loss: -8.167391376250999  params: [5.43823732 5.95177365]  gradients: -4.459941811036184\n",
      "epoch: 200  loss: -15.45248215456396  params: [10.52633444 11.03987077]  gradients: -4.459268880084492\n",
      "epoch: 300  loss: -22.736651439826346  params: [15.61423511 16.12777144]  gradients: -4.459268115117258\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#경사하강법\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m new_param \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m new_param\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X_train, y_train, learning_rate, num_epoch, tolerance, model, batch_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m gradients \u001b[38;5;241m=\u001b[39m batch_gradient(X_batch, y_batch, parameters, model)\n\u001b[0;32m     17\u001b[0m parameters \u001b[38;5;241m=\u001b[39m parameters \u001b[38;5;241m-\u001b[39m (learning_rate \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray(gradients) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(idx))\n\u001b[1;32m---> 18\u001b[0m new_loss \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#중단 조건\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(new_loss \u001b[38;5;241m-\u001b[39m loss) \u001b[38;5;241m<\u001b[39m tolerance:\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mbatch_loss\u001b[1;34m(X_set, y_set, parameters, loss_function, n)\u001b[0m\n\u001b[0;32m      4\u001b[0m     X \u001b[38;5;241m=\u001b[39m X_set\u001b[38;5;241m.\u001b[39miloc[i,:]\n\u001b[0;32m      5\u001b[0m     y \u001b[38;5;241m=\u001b[39m y_set\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[1;32m----> 6\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m n \u001b[38;5;66;03m#loss 평균값으로 계산\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mminus_log_cross_entropy_i\u001b[1;34m(X, y, parameters)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminus_log_cross_entropy_i\u001b[39m(X, y, parameters):\n\u001b[0;32m      2\u001b[0m     p \u001b[38;5;241m=\u001b[39m logistic(X,parameters)\n\u001b[1;32m----> 3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39my \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(p) \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39my) \u001b[38;5;241m*\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, learning_rate,num_epoch,tolerance,model,batch_size)\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m y_hat_NE \u001b[38;5;241m=\u001b[39m theta\u001b[38;5;241m.\u001b[39mdot(X\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m----> 2\u001b[0m y_hat_GD \u001b[38;5;241m=\u001b[39m \u001b[43mnew_param\u001b[49m\u001b[38;5;241m.\u001b[39mdot(X\u001b[38;5;241m.\u001b[39mT)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_param' is not defined"
     ]
    }
   ],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat_GD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m], y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.k\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#산점도\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m], y_hat_NE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-b\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNE\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#정규방정식\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m], \u001b[43my_hat_GD\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-r\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGD\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#경사하강법\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_hat_GD' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijgIcAdGLMbA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
